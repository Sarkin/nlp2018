{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lecture 1 - Keras",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Sarkin/nlp2018/blob/master/Copy_of_Lecture_1_Keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6xZha2jYQ-4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Введение в keras"
      ]
    },
    {
      "metadata": {
        "id": "F8RyqqwxMNK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "37QbrooERPEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sequential Model\n",
        "\n",
        "Обучить свою нейросеть просто! Нужно\n",
        "\n",
        "1.   Выбрать типы и последовательность слоев\n",
        "2.   Настроить параметры слоев (передав нужные в конструктор слоя или оставив вариант по умолчанию)\n",
        "3.   Выбрать оптимизатор и скомпилировать модель\n",
        "4.   Обучить модель!\n"
      ]
    },
    {
      "metadata": {
        "id": "_PL1yCgDatoO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Чтобы создать Sequential модель, просто позовите следующие строки:"
      ]
    },
    {
      "metadata": {
        "id": "CU_s-FGdastN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38316764-ea4d-447d-fe04-2bf7c677973d"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ukd2lt5_axi0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Слои теперь добавляются в модель последовательно, как будто это list:"
      ]
    },
    {
      "metadata": {
        "id": "YjBDZ-3mM-aM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F63KsSzwa9Hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Только что мы создали сеть с одним скрытым слоем. Сколько в ней обучаемых параметров?\n",
        "\n",
        "Посмотреть это можно с помощью метода"
      ]
    },
    {
      "metadata": {
        "id": "Fjw85Mpya7uQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6d21c825-74c5-4437-e047-934c8c645381"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 7,114\n",
            "Trainable params: 7,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YA4XjeN-R1tw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Почему столько параметров в слоях?* (input_dim x units) + (units bias весов)\n",
        "\n",
        "*Что за `None` вместо первого элемента `Output Shape`?*  Переменное количество входных векторов, по сути batch size"
      ]
    },
    {
      "metadata": {
        "id": "tLP-gPWObqD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Прежде чем обучать эту модель, её нужно скомпилировать:"
      ]
    },
    {
      "metadata": {
        "id": "13mCHIX_boaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tQglXsdgbsJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В NLP чаще всего ставятся задачи классификации, поэтому нужно запомнить такие функции потерь:\n",
        "\n",
        "\n",
        "*   **categorical_crossentropy** - для многоклассовой классификации, в качестве меток должны передаваться one-hot-encoding вектора\n",
        "*   **sparse_categorical_crossentropy** - аналогично предыдущему, но в качестве меток нужно передавать просто индексы соответствующих классов\n",
        "*   **binary_crossentropy** - для бинарной классификации\n",
        "\n",
        "\n",
        "В качестве оптимизатора обычно используют `sgd` или `adam`.\n"
      ]
    },
    {
      "metadata": {
        "id": "awWq_2TBeUDZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = np.random.randn(10000, 100)\n",
        "y_train = np.random.randint(0, 10, size=10000)\n",
        "X_test = np.random.randn(1000, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6ruHCW2bW2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a73e33f8-4b14-4f8a-8c75-09c3ca2b0b70"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 258us/step - loss: 2.5663 - acc: 0.1026\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 1s 150us/step - loss: 2.4418 - acc: 0.1088\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 156us/step - loss: 2.3806 - acc: 0.1143\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 1s 149us/step - loss: 2.3431 - acc: 0.1218\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 152us/step - loss: 2.3177 - acc: 0.1301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd65a6cef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "Fofu9T-o9IIp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Binary Classification\n",
        "\n",
        "Попробуем предсказать сентимент (положительность/отрицательность) imdb'шных ревью [keras: IMDB Movie reviews sentiment classification](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification)"
      ]
    },
    {
      "metadata": {
        "id": "q-MKXv5o5Xdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mmwhhax5k6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "31838731-895b-4b78-ceae-912e6159f28c"
      },
      "cell_type": "code",
      "source": [
        "NUM_WORDS = 10000\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gfSFPs6Y9Vhv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bag-of-words\n",
        "\n",
        "Начнем с простейшей модели"
      ]
    },
    {
      "metadata": {
        "id": "UINEdlb7555l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_bow(X):\n",
        "  X_bow = np.zeros((len(X), NUM_WORDS))\n",
        "  for i, review in enumerate(X):\n",
        "    for ind in review:\n",
        "      X_bow[i, ind] = 1\n",
        "  return X_bow\n",
        "\n",
        "X_train_bow, X_test_bow = convert_to_bow(X_train), convert_to_bow(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldWyutMw7kYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7329ffc9-c2cb-4458-89cc-e03c047c4f19"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=NUM_WORDS))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 1)                 10001     \n",
            "=================================================================\n",
            "Total params: 10,001\n",
            "Trainable params: 10,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J2ijwrONZFus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Как называется такая модель?* softmax classifier"
      ]
    },
    {
      "metadata": {
        "id": "SiDnmkwb73Ie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c186637b-ec7e-4454-b597-96eaf2481451"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_bow, y_train, \n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          validation_data=(X_test_bow, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 8s 336us/step - loss: 0.4362 - acc: 0.8456 - val_loss: 0.3476 - val_acc: 0.8807\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 8s 327us/step - loss: 0.2861 - acc: 0.9035 - val_loss: 0.3035 - val_acc: 0.8874\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 8s 326us/step - loss: 0.2396 - acc: 0.9201 - val_loss: 0.2894 - val_acc: 0.8888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbd04b8a438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Api85ure9o-X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convs\n",
        "\n",
        "Переходим к более сложным моделям."
      ]
    },
    {
      "metadata": {
        "id": "-3P3ZLYq9TSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "MAX_LEN = 400\n",
        "\n",
        "X_train_long = sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_test_long = sequence.pad_sequences(X_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztzPy24B-Gkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "01359524-e356-4e49-d943-ef094bebbf80"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Dropout, SpatialDropout1D, Conv1D, GlobalMaxPooling1D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "EMB_DIM = 50\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=NUM_WORDS, \n",
        "                    output_dim=EMB_DIM, \n",
        "                    input_length=MAX_LEN))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(),  # оптимизатор ещё и так можно передавать\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 400, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 398, 128)          19328     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 527,649\n",
            "Trainable params: 527,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RNYoNaou_Iyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d47c8e65-1570-48ae-b1d1-0adcf569591d"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_long, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test_long, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 14s 563us/step - loss: 0.4000 - acc: 0.8077 - val_loss: 0.2716 - val_acc: 0.8880\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 13s 527us/step - loss: 0.1969 - acc: 0.9251 - val_loss: 0.2629 - val_acc: 0.8902\n",
            "Epoch 3/5\n",
            " 5152/25000 [=====>........................] - ETA: 8s - loss: 0.0900 - acc: 0.9730"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 13s 528us/step - loss: 0.0870 - acc: 0.9724 - val_loss: 0.3046 - val_acc: 0.8892\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 13s 524us/step - loss: 0.0279 - acc: 0.9929 - val_loss: 0.3830 - val_acc: 0.8846\n",
            "Epoch 5/5\n",
            "15776/25000 [=================>............] - ETA: 3s - loss: 0.0068 - acc: 0.9989"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 13s 528us/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.4446 - val_acc: 0.8880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbce8c59f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "QEwbwOVWZcsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Попробуем улучшить качество.\n",
        "\n",
        "Добавим предобученные словные эмбеддинги.\n",
        "\n",
        "Чёрная магия, которую нужно для этого скастовать, выглядит как-нибудь так:"
      ]
    },
    {
      "metadata": {
        "id": "NnEoksQx_ypD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1669
        },
        "outputId": "21edf3a6-a576-466f-a610-568a3b39ddb4"
      },
      "cell_type": "code",
      "source": [
        "!pip install chakin\n",
        "\n",
        "import chakin\n",
        "chakin.search(lang='English')\n",
        "\n",
        "chakin.download(number=11, save_dir='./')\n",
        "\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "!pip install gensim\n",
        "!python -m gensim.scripts.glove2word2vec --input glove.6B.50d.txt --output glove.6B.50d.v2w.txt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chakin\n",
            "  Downloading https://files.pythonhosted.org/packages/45/a3/26d2b5b5b1700fb9923aadf6c8812c2128ab71a099c51855e92f994c49bd/chakin-0.0.6.tar.gz\n",
            "Requirement already satisfied: pandas>=0.20.1 in /usr/local/lib/python3.6/dist-packages (from chakin) (0.22.0)\n",
            "Collecting progressbar2>=3.20.0 (from chakin)\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/6f/acb2dd76f2c77527584bd3a4c2509782bb35c481c610521fc3656de5a9e0/progressbar2-3.38.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from chakin) (1.11.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (2018.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (1.14.3)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (2.5.3)\n",
            "Collecting python-utils>=2.3.0 (from progressbar2>=3.20.0->chakin)\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: chakin\n",
            "  Running setup.py bdist_wheel for chakin ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/0f/00/a8/306996e292c7a68d22e81d6350dc8adbb101b05163eb3b6915\n",
            "Successfully built chakin\n",
            "Installing collected packages: python-utils, progressbar2, chakin\n",
            "Successfully installed chakin-0.0.6 progressbar2-3.38.0 python-utils-2.3.0\n",
            "                   Name  Dimension                     Corpus VocabularySize  \\\n",
            "2          fastText(en)        300                  Wikipedia           2.5M   \n",
            "11         GloVe.6B.50d         50  Wikipedia+Gigaword 5 (6B)           400K   \n",
            "12        GloVe.6B.100d        100  Wikipedia+Gigaword 5 (6B)           400K   \n",
            "13        GloVe.6B.200d        200  Wikipedia+Gigaword 5 (6B)           400K   \n",
            "14        GloVe.6B.300d        300  Wikipedia+Gigaword 5 (6B)           400K   \n",
            "15       GloVe.42B.300d        300          Common Crawl(42B)           1.9M   \n",
            "16      GloVe.840B.300d        300         Common Crawl(840B)           2.2M   \n",
            "17    GloVe.Twitter.25d         25               Twitter(27B)           1.2M   \n",
            "18    GloVe.Twitter.50d         50               Twitter(27B)           1.2M   \n",
            "19   GloVe.Twitter.100d        100               Twitter(27B)           1.2M   \n",
            "20   GloVe.Twitter.200d        200               Twitter(27B)           1.2M   \n",
            "21  word2vec.GoogleNews        300          Google News(100B)           3.0M   \n",
            "\n",
            "      Method Language    Author  \n",
            "2   fastText  English  Facebook  \n",
            "11     GloVe  English  Stanford  \n",
            "12     GloVe  English  Stanford  \n",
            "13     GloVe  English  Stanford  \n",
            "14     GloVe  English  Stanford  \n",
            "15     GloVe  English  Stanford  \n",
            "16     GloVe  English  Stanford  \n",
            "17     GloVe  English  Stanford  \n",
            "18     GloVe  English  Stanford  \n",
            "19     GloVe  English  Stanford  \n",
            "20     GloVe  English  Stanford  \n",
            "21  word2vec  English    Google  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Test: 100% ||                                      | Time:  0:00:13  59.7 MiB/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 14.3MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/1c/898ab9025a1725d15c3b121f6c91642a2535acc5d363acb328d6b37ff6d1/boto3-1.7.40-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Collecting botocore<1.11.0,>=1.10.40 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/6f/e9c3981f8b7e93bfa4461b754563b0e917968947920d0bdcf2a7dcf77da2/botocore-1.10.40-py2.py3-none-any.whl (4.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.3MB 7.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 16.8MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.11.0,>=1.10.40->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.40->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.48.0 boto3-1.7.40 botocore-1.10.40 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n",
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'gensim.scripts.glove2word2vec' found in sys.modules after import of package 'gensim.scripts', but prior to execution of 'gensim.scripts.glove2word2vec'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2018-06-18 19:58:10,888 - glove2word2vec - INFO - running /usr/local/lib/python3.6/dist-packages/gensim/scripts/glove2word2vec.py --input glove.6B.50d.txt --output glove.6B.50d.v2w.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2018-06-18 19:58:11,854 - glove2word2vec - INFO - converting 400000 vectors from glove.6B.50d.txt to glove.6B.50d.v2w.txt\n",
            "2018-06-18 19:58:12,713 - glove2word2vec - INFO - Converted model with 400000 vectors and 50 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QlvSk2xrAr86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "12dbbcbc-581e-4f1a-dc57-340cda557490"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word_vectors = KeyedVectors.load_word2vec_format('glove.6B.50d.v2w.txt', binary=False)\n",
        "\n",
        "glove_word2index = {w : i for i, w in enumerate(word_vectors.index2word)}\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "word_index_rev = {word_index[x] : x for x in word_index}\n",
        "\n",
        "embedding_matrix = 0.05 * np.random.randn(NUM_WORDS, EMB_DIM)\n",
        "\n",
        "num_of_known_words = 0\n",
        "for word in word_index:\n",
        "  ind = word_index[word] + 3\n",
        "  if ind < NUM_WORDS and word in glove_word2index:\n",
        "    embedding_matrix[ind] = word_vectors.vectors[glove_word2index[word]]\n",
        "    num_of_known_words += 1\n",
        "\n",
        "print('Know', num_of_known_words, 'out of', NUM_WORDS)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 0us/step\n",
            "Know 9793 out of 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7cDUpRPkZnDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: Постройте ту же самую модель, но уже с передачей весов в `Embedding`.\n",
        "\n",
        "Обратите внимание на параметр `trainable`: во многих случаях дообучать эмбеддинги не нужно - для этого нужно передать `trainable=False`."
      ]
    },
    {
      "metadata": {
        "id": "Uk4LboZuDQ3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "20b715ff-d1fb-4864-f715-a48ede64ba96"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Embedding(input_dim=NUM_WORDS, \n",
        "                    output_dim=EMB_DIM, \n",
        "                    input_length=MAX_LEN,\n",
        "                    weights=[embedding_matrix]))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 400, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 398, 128)          19328     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 527,649\n",
            "Trainable params: 527,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7oLOKHOvFIlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f4d0463a-a681-425f-d3d2-ea939511dc37"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_long, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test_long, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 13s 539us/step - loss: 0.4362 - acc: 0.7908 - val_loss: 0.3113 - val_acc: 0.8650\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 13s 526us/step - loss: 0.2630 - acc: 0.8928 - val_loss: 0.2782 - val_acc: 0.8846\n",
            "Epoch 3/5\n",
            " 4896/25000 [====>.........................] - ETA: 8s - loss: 0.1738 - acc: 0.9310"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 13s 539us/step - loss: 0.1736 - acc: 0.9338 - val_loss: 0.2811 - val_acc: 0.8856\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 14s 543us/step - loss: 0.0999 - acc: 0.9648 - val_loss: 0.3616 - val_acc: 0.8749\n",
            "Epoch 5/5\n",
            "14688/25000 [================>.............] - ETA: 4s - loss: 0.0426 - acc: 0.9879"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 13s 530us/step - loss: 0.0434 - acc: 0.9870 - val_loss: 0.3876 - val_acc: 0.8812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcf48a5f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "HXQqJaifFhpx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM\n",
        "\n",
        "Попробуем теперь использовать рекуррентную сеть.\n",
        "\n",
        "Укоротим немного предложения для скорости:"
      ]
    },
    {
      "metadata": {
        "id": "hJGc8_0mHX4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 80\n",
        "\n",
        "X_train_short = sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_test_short = sequence.pad_sequences(X_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63lFedATUsi_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: постройте модель с LSTM.\n",
        "Первым должен так и идти слой эмбеддингов, а LSTM - применяться поверх него. Результатом будет последнее предсказание LSTM - с учётом всего контекста.\n",
        "\n",
        "Интересные параметры LSTM:\n",
        "`LSTM(units=?, dropout=0.0, recurrent_dropout=0.0, return_sequences=False)`\n",
        "\n",
        "Попробуйте `units=64` и дропауты в районе 0.2.\n"
      ]
    },
    {
      "metadata": {
        "id": "bbE2DiFdFkE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "48699700-310a-467c-a949-c06817cd2f21"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Embedding(input_dim=NUM_WORDS, \n",
        "                    output_dim=EMB_DIM, \n",
        "                    input_length=MAX_LEN,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False))\n",
        "\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 80, 50)            500000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                29440     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 529,505\n",
            "Trainable params: 29,505\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zfV68kl3F3_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25097
        },
        "outputId": "fceb51f8-6955-4e51-e1ba-ae2696e2e8d5"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_short, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(X_test_short, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "21920/25000 [=========================>....] - ETA: 23s - loss: 0.6218 - acc: 0.6515"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 241s 10ms/step - loss: 0.6131 - acc: 0.6601 - val_loss: 0.5249 - val_acc: 0.7322\n",
            "Epoch 2/15\n",
            "13088/25000 [==============>...............] - ETA: 1:29 - loss: 0.5286 - acc: 0.7352"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 241s 10ms/step - loss: 0.5156 - acc: 0.7438 - val_loss: 0.4689 - val_acc: 0.7740\n",
            "Epoch 3/15\n",
            " 9728/25000 [==========>...................] - ETA: 2:06 - loss: 0.4902 - acc: 0.7606"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 248s 10ms/step - loss: 0.4816 - acc: 0.7656 - val_loss: 0.4421 - val_acc: 0.7892\n",
            "Epoch 4/15\n",
            " 8480/25000 [=========>....................] - ETA: 2:00 - loss: 0.4701 - acc: 0.7763"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 229s 9ms/step - loss: 0.4684 - acc: 0.7738 - val_loss: 0.4306 - val_acc: 0.7962\n",
            "Epoch 5/15\n",
            " 8032/25000 [========>.....................] - ETA: 2:04 - loss: 0.4541 - acc: 0.7820"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 232s 9ms/step - loss: 0.4498 - acc: 0.7849 - val_loss: 0.4211 - val_acc: 0.7989\n",
            "Epoch 6/15\n",
            " 7872/25000 [========>.....................] - ETA: 2:10 - loss: 0.4448 - acc: 0.7893"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 241s 10ms/step - loss: 0.4366 - acc: 0.7926 - val_loss: 0.4055 - val_acc: 0.8093\n",
            "Epoch 7/15\n",
            " 7776/25000 [========>.....................] - ETA: 2:09 - loss: 0.4283 - acc: 0.8025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 237s 9ms/step - loss: 0.4261 - acc: 0.8000 - val_loss: 0.4052 - val_acc: 0.8093\n",
            "Epoch 8/15\n",
            " 7776/25000 [========>.....................] - ETA: 2:13 - loss: 0.4167 - acc: 0.8034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 238s 10ms/step - loss: 0.4156 - acc: 0.8046 - val_loss: 0.3938 - val_acc: 0.8155\n",
            "Epoch 9/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:09 - loss: 0.4131 - acc: 0.8045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 234s 9ms/step - loss: 0.4054 - acc: 0.8123 - val_loss: 0.3861 - val_acc: 0.8220\n",
            "Epoch 10/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:05 - loss: 0.4049 - acc: 0.8099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 228s 9ms/step - loss: 0.3979 - acc: 0.8165 - val_loss: 0.3950 - val_acc: 0.8185\n",
            "Epoch 11/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:05 - loss: 0.3847 - acc: 0.8262"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 232s 9ms/step - loss: 0.3905 - acc: 0.8215 - val_loss: 0.3778 - val_acc: 0.8255\n",
            "Epoch 12/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:08 - loss: 0.3824 - acc: 0.8222"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 237s 9ms/step - loss: 0.3808 - acc: 0.8258 - val_loss: 0.3799 - val_acc: 0.8266\n",
            "Epoch 13/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:11 - loss: 0.3695 - acc: 0.8349"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 239s 10ms/step - loss: 0.3744 - acc: 0.8290 - val_loss: 0.3715 - val_acc: 0.8283\n",
            "Epoch 14/15\n",
            " 7680/25000 [========>.....................] - ETA: 2:09 - loss: 0.3674 - acc: 0.8350"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 234s 9ms/step - loss: 0.3719 - acc: 0.8318 - val_loss: 0.4142 - val_acc: 0.8094\n",
            "Epoch 15/15\n",
            " 7680/25000 [========>.....................] - ETA: 2:09 - loss: 0.3645 - acc: 0.8314"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 233s 9ms/step - loss: 0.3640 - acc: 0.8328 - val_loss: 0.3739 - val_acc: 0.8280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcf5c281d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "fkrqb6lBV0Nu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM-CNN\n",
        "\n",
        "Вообще говоря, LSTM выдает не одно состояние, а много (внимание на `return_sequences`). Почему бы не попробовать использовать их все?\n",
        "\n",
        "**Задание**: реализуйте свертки и GlobalMaxPooling поверх выхода LSTM."
      ]
    },
    {
      "metadata": {
        "id": "65eD-ph4Vy_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "7d6c1b70-c4b0-4ade-c770-2a98f697598d"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Embedding(input_dim=NUM_WORDS, \n",
        "                    output_dim=EMB_DIM, \n",
        "                    input_length=MAX_LEN,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False))\n",
        "\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 80, 50)            500000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 80, 64)            29440     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 78, 128)           24704     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 562,465\n",
            "Trainable params: 62,465\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cQ-DUZf28XUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25625
        },
        "outputId": "a61a34bd-cc8d-4678-d3ca-e8dc0b116f5d"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_short, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(X_test_short, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "21920/25000 [=========================>....] - ETA: 23s - loss: 0.5715 - acc: 0.6925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 239s 10ms/step - loss: 0.5637 - acc: 0.6993 - val_loss: 0.4852 - val_acc: 0.7613\n",
            "Epoch 2/15\n",
            "13088/25000 [==============>...............] - ETA: 1:29 - loss: 0.4828 - acc: 0.7628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 237s 9ms/step - loss: 0.4833 - acc: 0.7649 - val_loss: 0.4453 - val_acc: 0.7886\n",
            "Epoch 3/15\n",
            " 9792/25000 [==========>...................] - ETA: 1:56 - loss: 0.4530 - acc: 0.7804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 240s 10ms/step - loss: 0.4493 - acc: 0.7865 - val_loss: 0.4212 - val_acc: 0.8034\n",
            "Epoch 4/15\n",
            " 8480/25000 [=========>....................] - ETA: 2:07 - loss: 0.4269 - acc: 0.7969"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 245s 10ms/step - loss: 0.4239 - acc: 0.8002 - val_loss: 0.4287 - val_acc: 0.7972\n",
            "Epoch 5/15\n",
            " 8000/25000 [========>.....................] - ETA: 2:09 - loss: 0.4108 - acc: 0.8099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 240s 10ms/step - loss: 0.4055 - acc: 0.8124 - val_loss: 0.3908 - val_acc: 0.8190\n",
            "Epoch 6/15\n",
            " 7808/25000 [========>.....................] - ETA: 2:11 - loss: 0.3772 - acc: 0.8283"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 240s 10ms/step - loss: 0.3856 - acc: 0.8260 - val_loss: 0.3803 - val_acc: 0.8270\n",
            "Epoch 7/15\n",
            " 7744/25000 [========>.....................] - ETA: 2:11 - loss: 0.3620 - acc: 0.8377"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 239s 10ms/step - loss: 0.3644 - acc: 0.8372 - val_loss: 0.3772 - val_acc: 0.8280\n",
            "Epoch 8/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:10 - loss: 0.3370 - acc: 0.8526"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 237s 9ms/step - loss: 0.3512 - acc: 0.8444 - val_loss: 0.3700 - val_acc: 0.8326\n",
            "Epoch 9/15\n",
            " 7744/25000 [========>.....................] - ETA: 2:10 - loss: 0.3346 - acc: 0.8530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 236s 9ms/step - loss: 0.3372 - acc: 0.8510 - val_loss: 0.3610 - val_acc: 0.8388\n",
            "Epoch 10/15\n",
            " 7712/25000 [========>.....................] - ETA: 2:10 - loss: 0.3236 - acc: 0.8543"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 239s 10ms/step - loss: 0.3280 - acc: 0.8549 - val_loss: 0.3777 - val_acc: 0.8377\n",
            "Epoch 11/15\n",
            " 7680/25000 [========>.....................] - ETA: 2:11 - loss: 0.3148 - acc: 0.8621"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 240s 10ms/step - loss: 0.3116 - acc: 0.8643 - val_loss: 0.3599 - val_acc: 0.8383\n",
            "Epoch 12/15\n",
            " 7648/25000 [========>.....................] - ETA: 2:18 - loss: 0.2919 - acc: 0.8737"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 250s 10ms/step - loss: 0.3063 - acc: 0.8656 - val_loss: 0.3698 - val_acc: 0.8395\n",
            "Epoch 13/15\n",
            " 7648/25000 [========>.....................] - ETA: 2:10 - loss: 0.2816 - acc: 0.8802"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 234s 9ms/step - loss: 0.2885 - acc: 0.8753 - val_loss: 0.3963 - val_acc: 0.8276\n",
            "Epoch 14/15\n",
            " 7680/25000 [========>.....................] - ETA: 2:08 - loss: 0.2743 - acc: 0.8829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 234s 9ms/step - loss: 0.2812 - acc: 0.8791 - val_loss: 0.3657 - val_acc: 0.8360\n",
            "Epoch 15/15\n",
            " 7680/25000 [========>.....................] - ETA: 2:09 - loss: 0.2681 - acc: 0.8848"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 234s 9ms/step - loss: 0.2708 - acc: 0.8828 - val_loss: 0.3769 - val_acc: 0.8413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcf5c52390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "lthq71WoPRZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Functional API\n",
        "\n",
        "Альтернативный (и более гибкий) вариант построения модели.\n",
        "\n",
        "Говоря по-сложному: у каждого объекта типа Layer переопределен метод `__call__`: его можно вызывать и передавать некоторый входной тензор. Возвращаемое значение - результат применения трансформации, задаваемой этим слоем, к данному входу (опять же тензор).\n",
        "\n",
        "А если по-простому - давайте построим ту же самую бессмысленную модель из самого начала ноутбука, но уже с новым апи."
      ]
    },
    {
      "metadata": {
        "id": "9s7epVrrPQdP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gEkqYnxyPgEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b723eeb1-0e79-4b50-b982-859d1a02109e"
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(100,))\n",
        "\n",
        "hidden_layer = Dense(units=64, activation='relu')(inputs)\n",
        "outputs = Dense(units=10, activation='softmax')(hidden_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 7,114\n",
            "Trainable params: 7,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TR7G0dHDRLsI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: сделайте модель, которая применяет свертки с шириной окна 2 и 3 к imdb dataset'у.\n",
        "\n",
        "Пригодится слой `concatenate` для объединения результатов разных типов сверток."
      ]
    },
    {
      "metadata": {
        "id": "Ux0XH6JBRLPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "cb08d0c3-8457-491c-da38-d1a162b6f532"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate\n",
        "\n",
        "inputs = Input(shape=(MAX_LEN,))\n",
        "\n",
        "embedding = Embedding(input_dim=NUM_WORDS, output_dim=EMB_DIM)(inputs)\n",
        "conv1 = Conv1D(filters=64, kernel_size=2, padding='valid', activation='relu', strides=1)(embedding)\n",
        "conv2 = Conv1D(filters=64, kernel_size=3, padding='valid', activation='relu', strides=1)(embedding)\n",
        "g1 = GlobalMaxPooling1D()(conv1)\n",
        "g2 = GlobalMaxPooling1D()(conv2)\n",
        "conc = concatenate([g1, g2], axis=1)\n",
        "\n",
        "dense = Dropout(0.2)(Dense(64, activation='relu')(conc))\n",
        "classes = Dense(1, activation='sigmoid')(dense)\n",
        "model = Model(inputs=inputs, outputs=classes)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(),  # оптимизатор ещё и так можно передавать\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 80)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 80, 50)       500000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 79, 64)       6464        embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 78, 64)       9664        embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 64)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 64)           0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128)          0           global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 64)           8256        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64)           0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1)            65          dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 524,449\n",
            "Trainable params: 524,449\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X_CL71kCSr8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1486
        },
        "outputId": "702e99e8-0043-42e2-b399-50e5e3f3454c"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train_short, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(X_test_short, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "25000/25000 [==============================] - 13s 523us/step - loss: 0.4589 - acc: 0.7705 - val_loss: 0.3550 - val_acc: 0.8405\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 12s 479us/step - loss: 0.2626 - acc: 0.8936 - val_loss: 0.3476 - val_acc: 0.8482\n",
            "Epoch 3/15\n",
            " 8160/25000 [========>.....................] - ETA: 6s - loss: 0.1210 - acc: 0.9613"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 478us/step - loss: 0.1331 - acc: 0.9544 - val_loss: 0.3960 - val_acc: 0.8430\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 12s 478us/step - loss: 0.0443 - acc: 0.9878 - val_loss: 0.5678 - val_acc: 0.8337\n",
            "Epoch 5/15\n",
            "20320/25000 [=======================>......] - ETA: 1s - loss: 0.0126 - acc: 0.9976"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 475us/step - loss: 0.0129 - acc: 0.9975 - val_loss: 0.6869 - val_acc: 0.8352\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 12s 476us/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.7606 - val_acc: 0.8309\n",
            "Epoch 7/15\n",
            "22528/25000 [==========================>...] - ETA: 1s - loss: 9.0024e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 489us/step - loss: 8.6234e-04 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.8436\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 12s 492us/step - loss: 2.5330e-04 - acc: 1.0000 - val_loss: 0.8114 - val_acc: 0.8442\n",
            "Epoch 9/15\n",
            "21056/25000 [========================>.....] - ETA: 1s - loss: 1.4467e-04 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 491us/step - loss: 1.4067e-04 - acc: 1.0000 - val_loss: 0.8489 - val_acc: 0.8437\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 12s 492us/step - loss: 8.3572e-05 - acc: 1.0000 - val_loss: 0.8856 - val_acc: 0.8435\n",
            "Epoch 11/15\n",
            "20192/25000 [=======================>......] - ETA: 1s - loss: 5.5246e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 492us/step - loss: 5.5999e-05 - acc: 1.0000 - val_loss: 0.9136 - val_acc: 0.8431\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 12s 483us/step - loss: 4.7265e-05 - acc: 1.0000 - val_loss: 0.9541 - val_acc: 0.8424\n",
            "Epoch 13/15\n",
            "21376/25000 [========================>.....] - ETA: 1s - loss: 2.4897e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 484us/step - loss: 2.4034e-05 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.8437\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 12s 488us/step - loss: 1.7694e-05 - acc: 1.0000 - val_loss: 1.0231 - val_acc: 0.8441\n",
            "Epoch 15/15\n",
            "20704/25000 [=======================>......] - ETA: 1s - loss: 1.9875e-05 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 12s 488us/step - loss: 1.9293e-05 - acc: 1.0000 - val_loss: 1.0723 - val_acc: 0.8421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbd69129e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "PSQ2yIq-IvQP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multiclass Classification\n",
        "\n",
        "Переходим к многоклассовой классификации: [keras: Reuters newswire topics classification](https://keras.io/datasets/#reuters-newswire-topics-classification).\n",
        "\n",
        "У нас тут 11,228 новостей размеченных по 46 топикам."
      ]
    },
    {
      "metadata": {
        "id": "dILzHGLPHjFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6ee727a2-abd9-49cd-bade-717144175159"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "NUM_WORDS = 10000\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=NUM_WORDS,\n",
        "                                                         test_split=0.2)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "num_classes = np.max(y_train) + 1\n",
        "print(num_classes, 'classes')\n",
        "\n",
        "print('Mean train example len:', np.mean([len(x) for x in X_train]))\n",
        "print('Mean test example len:', np.mean([len(x) for x in X_test]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 1s 0us/step\n",
            "8982 train sequences\n",
            "2246 test sequences\n",
            "46 classes\n",
            "Mean train example len: 145.5398574927633\n",
            "Mean test example len: 147.66117542297417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Od-ulZLtJHtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LEN = 150\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-C7uP-rMNIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание**: Попробуйте обучить собственную сеть на этих данных.\n",
        "\n",
        "Обратите внимание, что теперь уже многоклассовая классификация (вспоминаем про `sparse_categorical_crossentropy` и выходной слой с числом unit'ов, равным числу классов, и `softmax` активацией)."
      ]
    },
    {
      "metadata": {
        "id": "cjKlYJM_UaVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1c6e9c99-c11a-4ce9-8dc4-232b2e204069"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "print(MAX_LEN)\n",
        "\n",
        "model.add(Embedding(input_dim=NUM_WORDS, \n",
        "                    output_dim=EMB_DIM, \n",
        "                    input_length=MAX_LEN,\n",
        "                    weights=[embedding_matrix]))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 150, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 148, 128)          19328     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 46)                2990      \n",
            "=================================================================\n",
            "Total params: 530,574\n",
            "Trainable params: 530,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9jWV9MELlFoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "09b7eaa2-3501-40a9-bb8a-c637b1873bec"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/15\n",
            "8982/8982 [==============================] - 5s 532us/step - loss: 2.1879 - acc: 0.4488 - val_loss: 1.8589 - val_acc: 0.5205\n",
            "Epoch 2/15\n",
            "8982/8982 [==============================] - 3s 327us/step - loss: 1.7313 - acc: 0.5699 - val_loss: 1.6501 - val_acc: 0.6033\n",
            "Epoch 3/15\n",
            "8982/8982 [==============================] - 3s 328us/step - loss: 1.4575 - acc: 0.6497 - val_loss: 1.4858 - val_acc: 0.6451\n",
            "Epoch 4/15\n",
            "8982/8982 [==============================] - 3s 331us/step - loss: 1.2482 - acc: 0.6931 - val_loss: 1.3638 - val_acc: 0.6692\n",
            "Epoch 5/15\n",
            "7232/8982 [=======================>......] - ETA: 0s - loss: 1.1026 - acc: 0.7276"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8982/8982 [==============================] - 3s 336us/step - loss: 1.0939 - acc: 0.7269 - val_loss: 1.2940 - val_acc: 0.6910\n",
            "Epoch 6/15\n",
            "8982/8982 [==============================] - 3s 341us/step - loss: 0.9374 - acc: 0.7650 - val_loss: 1.2542 - val_acc: 0.6995\n",
            "Epoch 7/15\n",
            "8982/8982 [==============================] - 3s 345us/step - loss: 0.7901 - acc: 0.7996 - val_loss: 1.2242 - val_acc: 0.7115\n",
            "Epoch 8/15\n",
            "8982/8982 [==============================] - 3s 329us/step - loss: 0.6624 - acc: 0.8250 - val_loss: 1.1966 - val_acc: 0.7186\n",
            "Epoch 9/15\n",
            "8982/8982 [==============================] - 3s 330us/step - loss: 0.5716 - acc: 0.8491 - val_loss: 1.2321 - val_acc: 0.7235\n",
            "Epoch 10/15\n",
            "2176/8982 [======>.......................] - ETA: 2s - loss: 0.4890 - acc: 0.8644"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8982/8982 [==============================] - 3s 326us/step - loss: 0.4857 - acc: 0.8662 - val_loss: 1.2248 - val_acc: 0.7329\n",
            "Epoch 11/15\n",
            "8982/8982 [==============================] - 3s 329us/step - loss: 0.4109 - acc: 0.8874 - val_loss: 1.2267 - val_acc: 0.7289\n",
            "Epoch 12/15\n",
            "8982/8982 [==============================] - 3s 330us/step - loss: 0.3612 - acc: 0.9024 - val_loss: 1.3076 - val_acc: 0.7275\n",
            "Epoch 13/15\n",
            "8982/8982 [==============================] - 3s 334us/step - loss: 0.3281 - acc: 0.9100 - val_loss: 1.3434 - val_acc: 0.7231\n",
            "Epoch 14/15\n",
            "8982/8982 [==============================] - 3s 332us/step - loss: 0.2962 - acc: 0.9183 - val_loss: 1.3335 - val_acc: 0.7342\n",
            "Epoch 15/15\n",
            "1888/8982 [=====>........................] - ETA: 2s - loss: 0.2496 - acc: 0.9253"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8982/8982 [==============================] - 3s 328us/step - loss: 0.2767 - acc: 0.9224 - val_loss: 1.3886 - val_acc: 0.7386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbd503cb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "SixEDc_cb__f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Классификация на уровне символов\n",
        "\n",
        "Попробуем вернуться к imdb и предсказывать слова, используя их символьное представление."
      ]
    },
    {
      "metadata": {
        "id": "wZtr-ETMb_TG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be0563e0-0a4f-4577-e5e4-e6f8fb6a22f2"
      },
      "cell_type": "code",
      "source": [
        "NUM_WORDS = 50000\n",
        "\n",
        "print('Loading data...')\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "word_index_rev = {word_index[x] : x for x in word_index}"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aLq8Dv5SiE_f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Зададим отображение из символов в индексы."
      ]
    },
    {
      "metadata": {
        "id": "gE0uv6UmdzH8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def get_range(first_symb, last_symb):\n",
        "  return set(chr(c) for c in range(ord(first_symb), ord(last_symb) + 1))\n",
        "\n",
        "chars = get_range('a', 'z') | get_range('0', '9') | set(punctuation)\n",
        "char_index = {c : i for i, c in enumerate(chars)}\n",
        "\n",
        "def get_char_index(char, char_index):\n",
        "  return char_index[char] if char in char_index else len(char_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8RnGW9ziJ-v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Используя костыли, построим тензор, в котором на месте каждого элемента стоит последовательность его символов."
      ]
    },
    {
      "metadata": {
        "id": "hW6OmnCleLWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2f046f5-15ac-4acc-9746-519576afb040"
      },
      "cell_type": "code",
      "source": [
        "MAX_WORD_LEN = 15\n",
        "MAX_LINE_LEN = 100\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_LINE_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_LINE_LEN)\n",
        "\n",
        "def build_chars_tensor(X):\n",
        "  X_chars = np.zeros((len(X), MAX_LINE_LEN, MAX_WORD_LEN))\n",
        "  for i, line in enumerate(X):\n",
        "    for j, word_ind in enumerate(line):\n",
        "      if word_ind >= 3:\n",
        "        word = word_index_rev[word_ind]\n",
        "        word = word if len(word) < MAX_WORD_LEN else word[-MAX_WORD_LEN:]\n",
        "        X_chars[i, j, -len(word):] = [get_char_index(c, char_index) for c in word]\n",
        "  return X_chars\n",
        "\n",
        "X_chars_train = build_chars_tensor(X_train)\n",
        "X_chars_test = build_chars_tensor(X_test)\n",
        "\n",
        "print(X_chars_train.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 100, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ga-z7dmwidVo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Какая размерность получится, если применить к этому тензору ещё и слой эмбеддингов?*\n",
        "\n",
        "**Задание**: допишите код, попробуйте поклассифицировать с помощью него."
      ]
    },
    {
      "metadata": {
        "id": "5kH5wL3egWiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6485ee98-6952-43ee-bc7d-490e9ef1f234"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import TimeDistributed\n",
        "\n",
        "def build_chars_layer(chars_count, char_emb_dim=20, lstm_dim=32, dropout_rate=.2):\n",
        "  chars_embedding = Embedding(chars_count, char_emb_dim, name='char_embeddings')\n",
        "  chars_lstm = TimeDistributed(Bidirectional(\n",
        "      LSTM(lstm_dim, dropout=dropout_rate, recurrent_dropout=dropout_rate, name='char_LSTM')))\n",
        "  \n",
        "  def process_input(inp):\n",
        "    res = chars_embedding(inp)\n",
        "    return chars_lstm(res)\n",
        "  return process_input\n",
        "  \n",
        "chars = Input(shape=(None, MAX_WORD_LEN), name='chars')\n",
        "\n",
        "chars_level_embedding = build_chars_layer(chars_count = len(char_index) + 1)\n",
        "chars_output = chars_level_embedding(chars)\n",
        "\n",
        "lstm = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(chars_output)\n",
        "outputs = Dense(1, activation='sigmoid')(lstm)\n",
        "\n",
        "\n",
        "model = Model(inputs=chars, outputs=outputs)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "chars (InputLayer)           (None, None, 15)          0         \n",
            "_________________________________________________________________\n",
            "char_embeddings (Embedding)  (None, None, 15, 20)      1380      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 64)          13568     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 48,037\n",
            "Trainable params: 48,037\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PzgiMC45rX93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16050
        },
        "outputId": "115a8124-3ec3-4122-8f81-9743fa1c8bcb"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_chars_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=15,\n",
        "          validation_data=(X_chars_test, y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "21888/25000 [=========================>....] - ETA: 46s - loss: 0.6334 - acc: 0.6251"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 448s 18ms/step - loss: 0.6321 - acc: 0.6258 - val_loss: 0.6229 - val_acc: 0.6359\n",
            "Epoch 2/15\n",
            "13056/25000 [==============>...............] - ETA: 2:56 - loss: 0.6226 - acc: 0.6416"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 452s 18ms/step - loss: 0.6199 - acc: 0.6421 - val_loss: 0.6004 - val_acc: 0.6619\n",
            "Epoch 3/15\n",
            " 9696/25000 [==========>...................] - ETA: 3:39 - loss: 0.6135 - acc: 0.6471"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 436s 17ms/step - loss: 0.6049 - acc: 0.6566 - val_loss: 0.5919 - val_acc: 0.6742\n",
            "Epoch 4/15\n",
            " 8448/25000 [=========>....................] - ETA: 4:01 - loss: 0.6046 - acc: 0.6618"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 440s 18ms/step - loss: 0.5977 - acc: 0.6665 - val_loss: 0.5700 - val_acc: 0.6970\n",
            "Epoch 5/15\n",
            " 7968/25000 [========>.....................] - ETA: 4:09 - loss: 0.5870 - acc: 0.6845"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 448s 18ms/step - loss: 0.5800 - acc: 0.6859 - val_loss: 0.5575 - val_acc: 0.7024\n",
            "Epoch 6/15\n",
            " 7776/25000 [========>.....................] - ETA: 4:10 - loss: 0.5821 - acc: 0.6872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 443s 18ms/step - loss: 0.5670 - acc: 0.6977 - val_loss: 0.5574 - val_acc: 0.7022\n",
            "Epoch 7/15\n",
            " 7712/25000 [========>.....................] - ETA: 4:06 - loss: 0.5632 - acc: 0.6974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 437s 17ms/step - loss: 0.5610 - acc: 0.6986 - val_loss: 0.5233 - val_acc: 0.7343\n",
            "Epoch 8/15\n",
            " 7680/25000 [========>.....................] - ETA: 4:12 - loss: 0.5514 - acc: 0.7081"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 440s 18ms/step - loss: 0.5497 - acc: 0.7102 - val_loss: 0.5223 - val_acc: 0.7350\n",
            "Epoch 9/15\n",
            " 7680/25000 [========>.....................] - ETA: 4:08 - loss: 0.5438 - acc: 0.7189"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 437s 17ms/step - loss: 0.5390 - acc: 0.7191 - val_loss: 0.5085 - val_acc: 0.7431\n",
            "Epoch 10/15\n",
            " 7648/25000 [========>.....................] - ETA: 4:04 - loss: 0.5229 - acc: 0.7350"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 438s 18ms/step - loss: 0.5290 - acc: 0.7298 - val_loss: 0.5105 - val_acc: 0.7416\n",
            "Epoch 11/15\n",
            " 7616/25000 [========>.....................] - ETA: 4:13 - loss: 0.5246 - acc: 0.7336"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 444s 18ms/step - loss: 0.5173 - acc: 0.7393 - val_loss: 0.4989 - val_acc: 0.7467\n",
            "Epoch 12/15\n",
            " 7616/25000 [========>.....................] - ETA: 4:13 - loss: 0.5090 - acc: 0.7413"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 443s 18ms/step - loss: 0.5088 - acc: 0.7403 - val_loss: 0.4827 - val_acc: 0.7600\n",
            "Epoch 13/15\n",
            " 7616/25000 [========>.....................] - ETA: 4:14 - loss: 0.5057 - acc: 0.7383"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 445s 18ms/step - loss: 0.5055 - acc: 0.7431 - val_loss: 0.4780 - val_acc: 0.7650\n",
            "Epoch 14/15\n",
            " 7616/25000 [========>.....................] - ETA: 4:13 - loss: 0.5026 - acc: 0.7407"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 442s 18ms/step - loss: 0.4929 - acc: 0.7508 - val_loss: 0.4766 - val_acc: 0.7678\n",
            "Epoch 15/15\n",
            " 7616/25000 [========>.....................] - ETA: 4:11 - loss: 0.4891 - acc: 0.7576"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 441s 18ms/step - loss: 0.4841 - acc: 0.7582 - val_loss: 0.4635 - val_acc: 0.7716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbc7a0d1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "EAXwk9V8rXTk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}